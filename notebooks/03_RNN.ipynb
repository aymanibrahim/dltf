{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 03 Recurrent Neural Networks (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recurrent Neural Network Model \n",
    "- Long Short-Term Memory\n",
    "- Recursive Neural Tensor Network Theory\n",
    "- Applying Recurrent Networks to Language Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network (RNN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/representation.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/01_Intro/04_models/07_rnn.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/01_Intro/04_models/08_rnn_apps_1.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/01_Intro/04_models/09_rnn_apps_2.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/01_Intro/04_models/10_rnn_apps_3.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/01_sequential/01_sequentaial_data.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/01_sequential/02_sequentaial_problem_1.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/01_sequential/03_sequentaial_problem_2.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/01_sequential/04_sequentaial_problem_3.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/01_sequential/05_sequentaial_problem_4.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/01_sequential/06_recurs.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/02_rnn/01_recurrent_model.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/02_rnn/02_speech.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/02_rnn/03_captioning.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/02_rnn/04_sentiment.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/02_rnn/05_problems.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/03_lstm/01_rnn_problems.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/03_lstm/02_lstm_unit.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/03_lstm/03_flow_1.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/03_lstm/04_flow_2.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/03_lstm/05_flow_3.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sample LSTM network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-2-008c45951f32>:3: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'zeros:0' shape=(1, 4) dtype=float32>,\n",
       " <tf.Tensor 'zeros:0' shape=(1, 4) dtype=float32>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_CELL_SIZE = 4  # output size (dimension), which is same as hidden size in the cell\n",
    "\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(LSTM_CELL_SIZE, state_is_tuple=True)\n",
    "state = (tf.zeros([1,LSTM_CELL_SIZE]),)*2\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a sample input\n",
    ">batch_size = 1, and seq_len = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 2. 2. 2. 2. 2.]]\n"
     ]
    }
   ],
   "source": [
    "sample_input = tf.constant([[3,2,2,2,2,2]],dtype=tf.float32)\n",
    "print (sess.run(sample_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass the input to lstm_cell, and check the new state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "LSTMStateTuple(c=array([[-0.02789015,  0.27033073,  0.07677224, -0.08886454]],\n",
      "      dtype=float32), h=array([[-0.00314771,  0.12939826,  0.02333243, -0.00419557]],\n",
      "      dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"LSTM_sample1\"):\n",
    "    output, state_new = lstm_cell(sample_input, state)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print (sess.run(state_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The states has 2 parts, the new state c, and also the output h. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00314771  0.12939826  0.02333243 -0.00419557]]\n"
     ]
    }
   ],
   "source": [
    "print (sess.run(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Neural Tensor Network Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/03_lstm/06_stacked_1.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/03_lstm/07_stacked_2.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/03_lstm/08_training_lstm_1.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/03_lstm/09_training_lstm_2.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN with stacked LSTM\n",
    "> a 2-layer LSTM\n",
    "- the output of the first layer will become the input of the second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with a new session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "input_dim = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Create the stacked LSTM cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the first layer LTSM cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-38b727e88d65>:2: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "LSTM_CELL_SIZE_1 = 4 #4 hidden nodes\n",
    "cell1 = tf.contrib.rnn.LSTMCell(LSTM_CELL_SIZE_1)\n",
    "cells.append(cell1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the second layer LTSM cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_CELL_SIZE_2 = 5 #5 hidden nodes\n",
    "cell2 = tf.contrib.rnn.LSTMCell(LSTM_CELL_SIZE_2)\n",
    "cells.append(cell2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a multi-layer LTSM \n",
    ">use the <b>tf.contrib.rnnMultiRNNCell</b> function, it takes in multiple single layer LTSM cells to create a multilayer stacked LTSM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-4cb0e5b3e12a>:1: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "stacked_lstm = tf.contrib.rnn.MultiRNNCell(cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the RNN from stacked_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-2941a7a9b793>:3: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "# Batch size x time steps x features.\n",
    "data = tf.placeholder(tf.float32, [None, None, input_dim])\n",
    "output, state = tf.nn.dynamic_rnn(stacked_lstm, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input sequence length is 3, and the dimensionality of the inputs is 6. \n",
    "- The input should be a Tensor of shape: \n",
    " - [batch_size, max_time, dimension], in our case it would be (2, 3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2, 3, 4, 3, 2], [1, 2, 1, 1, 1, 2], [1, 2, 2, 2, 2, 2]],\n",
       " [[1, 2, 3, 4, 3, 2], [3, 2, 2, 1, 1, 2], [0, 0, 0, 0, 3, 2]]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Batch size x time steps x features.\n",
    "sample_input = [[[1,2,3,4,3,2], [1,2,1,1,1,2],[1,2,2,2,2,2]],[[1,2,3,4,3,2],[3,2,2,1,1,2],[0,0,0,0,3,2]]]\n",
    "sample_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send our input to network, and check the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "collapsed": false,
    "deletable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00169822, -0.01458727, -0.00715928,  0.03483444,\n",
       "         -0.03450711],\n",
       "        [ 0.0058762 , -0.01899449, -0.0293414 ,  0.08807264,\n",
       "         -0.07014848],\n",
       "        [ 0.01194308, -0.03331866, -0.03445432,  0.11736782,\n",
       "         -0.09132697]],\n",
       "\n",
       "       [[ 0.00169822, -0.01458727, -0.00715928,  0.03483444,\n",
       "         -0.03450711],\n",
       "        [ 0.01215527, -0.01703974, -0.04057174,  0.08619846,\n",
       "         -0.06469381],\n",
       "        [ 0.02278114, -0.03207559, -0.06227291,  0.1625186 ,\n",
       "         -0.1139788 ]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(output, feed_dict={data: sample_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is of shape (2, 3, 5), which corresponds to our 2 batches, 3 elements in our sequence, and the dimensionality of the output which is 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Recurrent Networks to Language Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/01_language_modelling_1.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/02_language_modelling_2.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/03_flow_1.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/04_flow_2.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/05_flow_3.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/06_flow_4.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/07_flow_5.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/08_lstm_network_1.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/09_lstm_network_2.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/10_lstm_network_3.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/11_lstm_network_4.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/12_word_embedding.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/13_similar_contexts.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/14_words_based_on_embedding_vectors.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/15_train_lstm_1.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/16_train_lstm_2.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p align=\"center\"> \n",
    "<img src=\"../images/03_RNN/04_language/17_train_lstm_3.png\", width=800, height=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Create a Recurrent Neural Network model based on the Long Short-Term Memory unit to train and benchmark on the Penn Treebank dataset.\n",
    "- Recurrent Network\n",
    " - a specialized model to process sequential data by keeping track of the \"state\" or context.\n",
    "- Creating a model focused on Language Modelling \n",
    " - a very relevant task that is the cornerstone of many different linguistic problems such as Speech Recognition, Machine Translation and Image Captioning. \n",
    "- use the Penn Treebank dataset for benchmarking Language Modelling models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Language Modelling?\n",
    "> the task of assigning probabilities to sequences of words. \n",
    "- This means that, given a context of one or a sequence of words in the language the model was trained on, the model should provide the next most probable words or sequence of words that follows from the given sequence of words the sentence. \n",
    "- Language Modelling is one of the most important tasks in Natural Language Processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Penn Treebank Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a dataset maintained by the University of Pennsylvania. \n",
    "- there are over four million and eight hundred thousand annotated words in it, all corrected by humans. \n",
    "- composed of many different sources, from abstracts of Department of Energy papers to texts from the Library of America. \n",
    "-  it is verifiably correct and of such a huge size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a way of representing sentence structures or words as n-dimensional vectors (where n is a reasonably high number, such as 200 or 500) of real numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build LSTM model for Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# !wget -q -O ../data/ptb.zip https://ibm.box.com/shared/static/z2yvmhbskc45xd2a9a4kkn6hg4g4kj5r.zip\n",
    "# !unzip -o ../data/ptb.zip -d ../data\n",
    "# !cp ../data/ptb/reader.py ../utils/reader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../utils'))\n",
    "sys.path.insert(1, os.path.abspath('../utils/reader'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and extract the simple-examples dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# !wget -q -O ../data/simple-examples.tgz http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz \n",
    "# !tar -xzf ../data/simple-examples.tgz -C ../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Initial weight scale\n",
    "init_scale = 0.1\n",
    "\n",
    "#Initial learning rate\n",
    "learning_rate = 1.0\n",
    "\n",
    "#Maximum permissible norm for the gradient (For gradient clipping -- another measure against Exploding Gradients)\n",
    "max_grad_norm = 5\n",
    "\n",
    "#The number of layers in our model\n",
    "num_layers = 2\n",
    "\n",
    "#The total number of recurrence steps, also known as the number of layers when our RNN is \"unfolded\"\n",
    "num_steps = 20\n",
    "\n",
    "#The number of processing units (neurons) in the hidden layers\n",
    "hidden_size_l1 = 256\n",
    "hidden_size_l2 = 128\n",
    "\n",
    "#The maximum number of epochs trained with the initial learning rate\n",
    "max_epoch_decay_lr = 4\n",
    "\n",
    "#The total number of epochs in training\n",
    "max_epoch = 15\n",
    "\n",
    "#The probability for keeping data in the Dropout Layer (This is an optimization, but is outside our scope for this notebook!)\n",
    "#At 1, we ignore the Dropout Layer wrapping.\n",
    "keep_prob = 1\n",
    "\n",
    "#The decay for the learning rate\n",
    "decay = 0.5\n",
    "\n",
    "#The size for each batch of data\n",
    "batch_size = 60\n",
    "\n",
    "#The size of our vocabulary\n",
    "vocab_size = 10000\n",
    "embeding_vector_size = 200\n",
    "\n",
    "#Training flag to separate training from testing\n",
    "is_training = 1\n",
    "\n",
    "#Data directory for our dataset\n",
    "data_dir = \"../data/simple-examples/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network structure:\n",
    "<ul>\n",
    "    <li>In this network, the number of LSTM cells are 2. To give the model more expressive power, we can add multiple layers of LSTMs to process the data. The output of the first layer will become the input of the second and so on.\n",
    "    </li>\n",
    "    <li>The recurrence steps is 20, that is, when our RNN is \"Unfolded\", the recurrence step is 20.</li>   \n",
    "    <li>the structure is like:\n",
    "        <ul>\n",
    "            <li>200 input units -> [200x200] Weight -> 200 Hidden units (first layer) -> [200x200] Weight matrix  -> 200 Hidden units (second layer) ->  [200] weight Matrix -> 200 unit output</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Train data is a list of words, of size 929589, represented by numbers, e.g. [9971, 9972, 9974, 9975,...]</li>\n",
    "    <li>We read data as mini-batch of size b=30. Assume the size of each sentence is 20 words (num_steps = 20). Then it will take $$floor(\\frac{N}{b \\times h})+1=1548$$ iterations for the learner to go through all sentences once. Where N is the size of the list of words, b is batch size, andh is size of each sentence. So, the number of iterators is 1548\n",
    "    </li>\n",
    "    <li>Each batch data is read from train dataset of size 600, and shape of [30x20]</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start an interactive session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ayman/projects/cognitiveclass/deep-learning/tensorflow/stp/utils/reader.py:30: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reads the data and separates it into training data, validation data and testing data\n",
    "raw_data = reader.ptb_raw_data(data_dir)\n",
    "train_data, valid_data, test_data, vocab, word_to_id = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929589"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett', 'fromstein', 'gitano', 'guterman', 'hydro-quebec', 'ipo', 'kia', 'memotec', 'mlx', 'nahb', 'punts', 'rake', 'regatta', 'rubens', 'sim', 'snack-food', 'ssangyong', 'swapo', 'wachter', '<eos>', 'pierre', '<unk>', 'N', 'years', 'old', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', 'N', '<eos>', 'mr.', '<unk>', 'is', 'chairman', 'of', '<unk>', 'n.v.', 'the', 'dutch', 'publishing', 'group', '<eos>', 'rudolph', '<unk>', 'N', 'years', 'old', 'and', 'former', 'chairman', 'of', 'consolidated', 'gold', 'fields', 'plc', 'was', 'named', 'a', 'nonexecutive', 'director', 'of', 'this', 'british', 'industrial', 'conglomerate', '<eos>', 'a', 'form', 'of', 'asbestos', 'once', 'used', 'to', 'make', 'kent', 'cigarette', 'filters', 'has', 'caused', 'a', 'high', 'percentage', 'of', 'cancer', 'deaths', 'among', 'a', 'group', 'of']\n"
     ]
    }
   ],
   "source": [
    "def id_to_word(id_list):\n",
    "    line = []\n",
    "    for w in id_list:\n",
    "        for word, wid in word_to_id.items():\n",
    "            if wid == w:\n",
    "                line.append(word)\n",
    "    return line            \n",
    "                \n",
    "\n",
    "print(id_to_word(train_data[0:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Read one mini-batch and feed the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "itera = reader.ptb_iterator(train_data, batch_size, num_steps)\n",
    "first_touple = itera.__next__()\n",
    "x = first_touple[0]\n",
    "y = first_touple[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 20)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Look at 3 sentences of our input x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9970, 9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984,\n",
       "        9986, 9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995],\n",
       "       [ 901,   33, 3361,    8, 1279,  437,  597,    6,  261, 4276, 1089,\n",
       "           8, 2836,    2,  269,    4, 5526,  241,   13, 2420],\n",
       "       [2654,    6,  334, 2886,    4,    1,  233,  711,  834,   11,  130,\n",
       "         123,    7,  514,    2,   63,   10,  514,    8,  605]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Define 2 place holders to feed them with mini-batchs\n",
    "> that is x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "_input_data = tf.placeholder(tf.int32, [batch_size, num_steps]) #[30#20]\n",
    "_targets = tf.placeholder(tf.int32, [batch_size, num_steps]) #[30#20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Define feed dictionary\n",
    ">a dictionary to feed the placeholders with our first mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "feed_dict = {_input_data:x, _targets:y}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Use eed dictionary to feed <code>\\_input\\_data</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9970, 9971, 9972, ..., 9993, 9994, 9995],\n",
       "       [ 901,   33, 3361, ...,  241,   13, 2420],\n",
       "       [2654,    6,  334, ...,  514,    8,  605],\n",
       "       ...,\n",
       "       [7831,   36, 1678, ...,    4, 4558,  157],\n",
       "       [  59, 2070, 2433, ...,  400,    1, 1173],\n",
       "       [2097,    3,    2, ..., 2043,   23,    1]], dtype=int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(_input_data, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Create the stacked LSTM\n",
    "> a 2 layer LSTM network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "lstm_cell_l1 = tf.contrib.rnn.BasicLSTMCell(hidden_size_l1, forget_bias=0.0)\n",
    "lstm_cell_l2 = tf.contrib.rnn.BasicLSTMCell(hidden_size_l2, forget_bias=0.0)\n",
    "stacked_lstm = tf.contrib.rnn.MultiRNNCell([lstm_cell_l1, lstm_cell_l2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the states of the nework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each LSTM, there are 2 state matrices, c_state and m_state. c_state and m_state represent \"Memory State\" and \"Cell State\". \n",
    "- Each hidden layer, has a vector of size 30, which keeps the states. so, for 200 hidden units in each LSTM, we have a matrix of size [30x200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros:0' shape=(60, 256) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(60, 256) dtype=float32>),\n",
       " LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros:0' shape=(60, 128) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros_1:0' shape=(60, 128) dtype=float32>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_initial_state = stacked_lstm.zero_state(batch_size, tf.float32)\n",
    "_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LSTMStateTuple(c=array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), h=array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)),\n",
       " LSTMStateTuple(c=array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), h=array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(_initial_state, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use word2vec approach. \n",
    "> a layer in our LSTM network, where the word IDs will be represented as a dense representation before feeding to the LSTM.\n",
    "- The embedded vectors also get updated during the training process of the deep neural network. \n",
    "- create the embeddings for our input data. embedding_vocab is matrix of [10000x200] for all 10000 unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "embedding_vocab = tf.get_variable(\"embedding_vocab\", [vocab_size, embeding_vector_size])  #[10000x200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the embedding_words variable with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00608553,  0.02316697,  0.00850037, ...,  0.0097343 ,\n",
       "        -0.02110031, -0.0094935 ],\n",
       "       [ 0.00726549,  0.01412515,  0.01587074, ...,  0.01387824,\n",
       "        -0.00384138, -0.00040491],\n",
       "       [ 0.00334261, -0.01266769,  0.00938902, ...,  0.00973993,\n",
       "        -0.02375495, -0.01261522],\n",
       "       ...,\n",
       "       [ 0.02279766, -0.02080852,  0.00248465, ..., -0.01013499,\n",
       "        -0.00907152, -0.0035477 ],\n",
       "       [-0.01232858,  0.01818559, -0.02100804, ...,  0.00377212,\n",
       "        -0.01491393, -0.00859111],\n",
       "       [-0.00568854,  0.01561152,  0.02232993, ..., -0.00098379,\n",
       "         0.00887893, -0.01299976]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "session.run(embedding_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>embedding_lookup()</b> finds the embedded values for our batch of 30x20 words. \n",
    "- It  goes to each row of <code>input_data</code>, and for each word in the row/sentence, finds the correspond vector in <code>embedding_dic<code>. <br>\n",
    "    \n",
    "- It creates a [30x20x200] tensor, so, the first element of <b>inputs</b> (the first sentence), is a matrix of 20x200, which each row of it, is vector representing a word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup/Identity:0' shape=(60, 20, 200) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define where to get the data for our embeddings from\n",
    "inputs = tf.nn.embedding_lookup(embedding_vocab, _input_data)  #shape=(30, 20, 200) \n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0099417 , -0.00499686, -0.02301759, ...,  0.01160837,\n",
       "        -0.00540734, -0.00616114],\n",
       "       [-0.02352976,  0.00749895, -0.00054963, ...,  0.02211174,\n",
       "         0.02308293,  0.00370267],\n",
       "       [ 0.00198179, -0.01382315, -0.0206541 , ...,  0.00770796,\n",
       "         0.00837734,  0.02227392],\n",
       "       ...,\n",
       "       [-0.01112434,  0.01279724, -0.01426055, ..., -0.00376415,\n",
       "         0.00799492, -0.01259819],\n",
       "       [ 0.01110651, -0.0124359 ,  0.00858598, ..., -0.00759171,\n",
       "        -0.01447613, -0.02304328],\n",
       "       [-0.02397435,  0.00478216, -0.00107834, ..., -0.01443287,\n",
       "        -0.00390139, -0.01575679]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(inputs[0], feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Constructing Recurrent Neural Networks</h3>\n",
    "<b>tf.nn.dynamic_rnn()</b> creates a recurrent neural network using <b>stacked_lstm</b>. \n",
    "\n",
    "The input should be a Tensor of shape: [batch_size, max_time, embedding_vector_size], in our case it would be (30, 20, 200)\n",
    "\n",
    "This method, returns a pair (outputs, new_state) where:\n",
    "<ul>\n",
    "    <li><b>outputs</b>: is a length T list of outputs (one for each input), or a nested tuple of such elements.</li>\n",
    "    <li><b>new_state</b>: is the final state.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs, new_state =  tf.nn.dynamic_rnn(stacked_lstm, inputs, initial_state=_initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output of the stackedLSTM comes from 200 hidden_layer, and in each time step(=20), one of them get activated. we use the linear activation to map the 200 hidden layer to a [?x10 matrix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.1330728e-04,  1.3642707e-04,  5.5613846e-04, ...,\n",
       "         5.4796221e-04, -2.7817587e-04, -2.1321908e-05],\n",
       "       [ 6.8880683e-05,  2.8249942e-04, -9.9480210e-05, ...,\n",
       "        -3.9396962e-04, -7.5927557e-04,  3.4617231e-04],\n",
       "       [ 5.0672889e-04,  7.6626748e-04, -5.7040941e-04, ...,\n",
       "        -3.5147878e-04, -1.0085328e-03, -9.9795907e-06],\n",
       "       ...,\n",
       "       [-5.0024228e-04,  8.5794012e-04,  5.1374576e-04, ...,\n",
       "         5.5179058e-04,  5.7027861e-04,  7.0401275e-04],\n",
       "       [-1.0561847e-04,  7.0982624e-04,  1.0001612e-05, ...,\n",
       "        -8.7939239e-05, -1.9501518e-04,  6.6624512e-04],\n",
       "       [-3.9128942e-04,  1.3004150e-03, -1.6202097e-04, ...,\n",
       "        -5.1277975e-04, -4.8569913e-04,  5.9467653e-04]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "session.run(outputs[0], feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- flatten the outputs to be able to connect it softmax layer. Lets reshape the output tensor from  [30 x 20 x 200] to [600 x 200].\n",
    "\n",
    "<b>Notice:</b> Imagine our output is 3-d tensor as following (of course each <code>sen_x_word_y</code> is a an embedded vector by itself): \n",
    "<ul>\n",
    "    <li>sentence 1: [[sen1word1], [sen1word2], [sen1word3], ..., [sen1word20]]</li> \n",
    "    <li>sentence 2: [[sen2word1], [sen2word2], [sen2word3], ..., [sen2word20]]</li>   \n",
    "    <li>sentence 3: [[sen3word1], [sen3word2], [sen3word3], ..., [sen3word20]]</li>  \n",
    "    <li>...  </li>\n",
    "    <li>sentence 30: [[sen30word1], [sen30word2], [sen30word3], ..., [sen30word20]]</li>   \n",
    "</ul>\n",
    "Now, the flatten would convert this 3-dim tensor to:\n",
    "\n",
    "[ [sen1word1], [sen1word2], [sen1word3], ..., [sen1word20],[sen2word1], [sen2word2], [sen2word3], ..., [sen2word20], ..., [sen30word20] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape:0' shape=(1200, 128) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tf.reshape(outputs, [-1, hidden_size_l2])\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a logistic unit\n",
    ">create a logistic unit to return the probability of the output word in our vocabulary with 1000 words. \n",
    "\n",
    "$$Softmax = [600 \\times 200] * [200 \\times 1000] + [1 \\times 1000] \\Longrightarrow [600 \\times 1000]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "softmax_w = tf.get_variable(\"softmax_w\", [hidden_size_l2, vocab_size]) #[200x1000]\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [vocab_size]) #[1x1000]\n",
    "logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "prob = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the probability of observing words for t=0 to t=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the output:  (1200, 10000)\n",
      "The probability of observing words in t=0 to t=20 [[1.00702666e-04 9.99969343e-05 9.95023656e-05 ... 9.96704330e-05\n",
      "  1.00754478e-04 1.00848010e-04]\n",
      " [1.00704769e-04 9.99948024e-05 9.95033115e-05 ... 9.96637464e-05\n",
      "  1.00750920e-04 1.00846511e-04]\n",
      " [1.00706500e-04 9.99955591e-05 9.95031951e-05 ... 9.96655508e-05\n",
      "  1.00744517e-04 1.00851394e-04]\n",
      " ...\n",
      " [1.00685378e-04 1.00004079e-04 9.95139999e-05 ... 9.96648669e-05\n",
      "  1.00748483e-04 1.00883946e-04]\n",
      " [1.00688107e-04 1.00004916e-04 9.95141891e-05 ... 9.96689414e-05\n",
      "  1.00745820e-04 1.00881145e-04]\n",
      " [1.00698315e-04 9.99986587e-05 9.95065348e-05 ... 9.96568488e-05\n",
      "  1.00750840e-04 1.00872188e-04]]\n"
     ]
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "output_words_prob = session.run(prob, feed_dict)\n",
    "print(\"shape of the output: \", output_words_prob.shape)\n",
    "print(\"The probability of observing words in t=0 to t=20\", output_words_prob[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">What is the word correspond to the probability output? \n",
    "- use the maximum probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1966, 1966, 6342, 6342, 6753, 2334, 2334, 2334, 3765, 7769, 7769,\n",
       "       7769, 6753,  524,  524, 8928, 8928, 7445, 7445,  709])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(output_words_prob[0:20], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what is the ground truth for the first word of first sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984, 9986,\n",
       "       9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995, 9996], dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Get it from target tensor, if you want to find the embedding vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9971, 9972, 9974, 9975, 9976, 9980, 9981, 9982, 9983, 9984, 9986,\n",
       "       9987, 9988, 9989, 9991, 9992, 9993, 9994, 9995, 9996], dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targ = session.run(_targets, feed_dict) \n",
    "targ[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How similar the predicted words are to the target words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now we have to define our objective function, to calculate the similarity of predicted values to ground truth, and then, penalize the model with the error. Our objective is to minimize loss function, that is, to minimize the average negative log probability of the target words:\n",
    "\n",
    "$$\\text{loss} = -\\frac{1}{N}\\sum_{i=1}^{N} \\ln p_{\\text{target}_i}$$\n",
    "\n",
    "This function is already implemented and available in TensorFlow through <b>sequence_loss_by_example</b>. It calculates the weighted cross-entropy loss for <b>logits</b> and the <b>target</b> sequence.  \n",
    "\n",
    "The arguments of this function are:  \n",
    "<ul>\n",
    "    <li>logits: List of 2D Tensors of shape [batch_size x num_decoder_symbols].</li>  \n",
    "    <li>targets: List of 1D batch-sized int32 Tensors of the same length as logits.</li>   \n",
    "    <li>weights: List of 1D batch-sized float-Tensors of the same length as logits.</li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits], [tf.reshape(_targets, [-1])],[tf.ones([batch_size * num_steps])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "loss is a 1D batch-sized float Tensor [600x1]: The log-perplexity for each sequence. Lets look at the first 10 values of loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.221513, 9.200958, 9.20281 , 9.222314, 9.212445, 9.220491,\n",
       "       9.211142, 9.211143, 9.196133, 9.21785 ], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(loss, feed_dict)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss as average of the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184.23598"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = tf.reduce_sum(loss) / batch_size\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(cost, feed_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "To do training for our network, we have to take the following steps:\n",
    "<ol>\n",
    "    <li>Define the optimizer.</li>\n",
    "    <li>Extract variables that are trainable.</li>\n",
    "    <li>Calculate the gradients based on the loss function.</li>\n",
    "    <li>Apply the optimizer to the variables/gradients tuple.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h4>1. Define Optimizer</h4>\n",
    "\n",
    "<b>GradientDescentOptimizer</b> constructs a new gradient descent optimizer. Later, we use constructed <b>optimizer</b> to compute gradients for a loss and apply gradients to variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a variable for the learning rate\n",
    "lr = tf.Variable(0.0, trainable=False)\n",
    "# Create the gradient descent optimizer with our learning rate\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n",
    "<h4>2. Trainable Variables</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Defining a variable, if you passed <i>trainable=True</i>, the variable constructor automatically adds new variables to the graph collection <b>GraphKeys.TRAINABLE_VARIABLES</b>. Now, using <i>tf.trainable_variables()</i> you can get all variables created with <b>trainable=True</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'LSTM_sample1/basic_lstm_cell/kernel:0' shape=(10, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'LSTM_sample1/basic_lstm_cell/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0' shape=(10, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0' shape=(9, 20) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0' shape=(20,) dtype=float32_ref>,\n",
       " <tf.Variable 'embedding_vocab:0' shape=(10000, 200) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(456, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(384, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'softmax_w:0' shape=(128, 10000) dtype=float32_ref>,\n",
       " <tf.Variable 'softmax_b:0' shape=(10000,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all TensorFlow variables marked as \"trainable\" (i.e. all of them except _lr, which we just created)\n",
    "tvars = tf.trainable_variables()\n",
    "tvars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Find the name and scope of all variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LSTM_sample1/basic_lstm_cell/kernel:0',\n",
       " 'LSTM_sample1/basic_lstm_cell/bias:0',\n",
       " 'rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0',\n",
       " 'rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0',\n",
       " 'rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0',\n",
       " 'rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0',\n",
       " 'embedding_vocab:0',\n",
       " 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0',\n",
       " 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0',\n",
       " 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0',\n",
       " 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0',\n",
       " 'softmax_w:0',\n",
       " 'softmax_b:0']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tvars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h4>3. Calculate the gradients based on the loss function</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h4>Gradient</h4>:\n",
    "The gradient of a function is the slope of its derivative (line), or in other words, the rate of change of a function. It's a vector (a direction to move) that points in the direction of greatest increase of the function, and calculated by the <b>derivative</b> operation.\n",
    "\n",
    "First lets recall the gradient function using an toy example:\n",
    "$$ z = \\left(2x^2 + 3xy\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_x = tf.placeholder(tf.float32)\n",
    "var_y = tf.placeholder(tf.float32) \n",
    "func_test = 2.0 * var_x * var_x + 3.0 * var_x * var_y\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(func_test, {var_x:1.0,var_y:2.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The <b>tf.gradients()</b> function allows you to compute the symbolic gradient of one tensor with respect to one or more other tensorsincluding variables. <b>tf.gradients(func, xs)</b> constructs symbolic partial derivatives of sum of <b>func</b> w.r.t. <i>x</i> in <b>xs</b>. \n",
    "\n",
    "Now, lets look at the derivitive w.r.t. <b>var_x</b>:\n",
    "$$ \\frac{\\partial \\:}{\\partial \\:x}\\left(2x^2 + 3xy\\right) = 4x + 3y $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.0]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_grad = tf.gradients(func_test, [var_x])\n",
    "session.run(var_grad, {var_x:1.0,var_y:2.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "the derivative w.r.t. <b>var_y</b>:\n",
    "$$ \\frac{\\partial \\:}{\\partial \\:x}\\left(2x^2 + 3xy\\right) = 3x $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_grad = tf.gradients(func_test, [var_y])\n",
    "session.run(var_grad, {var_x:1.0, var_y:2.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Look at gradients w.r.t all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " <tensorflow.python.framework.ops.IndexedSlices at 0x7f6ac8d97dd8>,\n",
       " <tf.Tensor 'gradients_2/rnn_1/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/MatMul/Enter_grad/b_acc_3:0' shape=(456, 1024) dtype=float32>,\n",
       " <tf.Tensor 'gradients_2/rnn_1/while/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_3:0' shape=(1024,) dtype=float32>,\n",
       " <tf.Tensor 'gradients_2/rnn_1/while/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/MatMul/Enter_grad/b_acc_3:0' shape=(384, 512) dtype=float32>,\n",
       " <tf.Tensor 'gradients_2/rnn_1/while/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/BiasAdd/Enter_grad/b_acc_3:0' shape=(512,) dtype=float32>,\n",
       " <tf.Tensor 'gradients_2/MatMul_grad/MatMul_1:0' shape=(128, 10000) dtype=float32>,\n",
       " <tf.Tensor 'gradients_2/add_grad/Reshape_1:0' shape=(10000,) dtype=float32>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gradients(cost, tvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grad_t_list = tf.gradients(cost, tvars)\n",
    "#sess.run(grad_t_list,feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "now, we have a list of tensors, t-list. We can use it to find clipped tensors. <b>clip_by_global_norm</b> clips values of multiple tensors by the ratio of the sum of their norms.\n",
    "\n",
    "<b>clip_by_global_norm</b> get <i>t-list</i> as input and returns 2 things:\n",
    "<ul>\n",
    "    <li>a list of clipped tensors, so called <i>list_clipped</i></li> \n",
    "    <li>the global norm (global_norm) of all tensors in t_list</li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:286: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " <tensorflow.python.framework.ops.IndexedSlices at 0x7f6ac8c17f60>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_7:0' shape=(456, 1024) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_8:0' shape=(1024,) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_9:0' shape=(384, 512) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_10:0' shape=(512,) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_11:0' shape=(128, 10000) dtype=float32>,\n",
       " <tf.Tensor 'clip_by_global_norm/clip_by_global_norm/_12:0' shape=(10000,) dtype=float32>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the gradient clipping threshold\n",
    "grads, _ = tf.clip_by_global_norm(grad_t_list, max_grad_norm)\n",
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# session.run(grads, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h4>4. Apply the optimizer to the variables / gradients tuple.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the training TensorFlow Operation through our optimizer\n",
    "train_op = optimizer.apply_gradients(zip(grads, tvars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "session.run(train_op, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Class that represents the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<ul>\n",
    "    <li>We have to create the model in accordance with our defined hyperparameters</li>\n",
    "    <li>We have to create the placeholders for our input data and expected outputs (the real data)</li>\n",
    "    <li>We have to create the LSTM cell structure and connect them with our RNN structure</li>\n",
    "    <li>We have to create the word embeddings and point them to the input data</li>\n",
    "    <li>We have to create the input structure for our RNN</li>\n",
    "    <li>We have to instantiate our RNN model and retrieve the variable in which we should expect our outputs to appear</li>\n",
    "    <li>We need to create a logistic structure to return the probability of our words</li>\n",
    "    <li>We need to create the loss and cost functions for our optimizer to work, and then create the optimizer</li>\n",
    "    <li>And finally, we need to create a training operation that can be run to actually train our model</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "class PTBModel(object):\n",
    "\n",
    "    def __init__(self, action_type):\n",
    "        ######################################\n",
    "        # Setting parameters for ease of use #\n",
    "        ######################################\n",
    "        self.batch_size = batch_size\n",
    "        self.num_steps = num_steps\n",
    "        self.hidden_size_l1 = hidden_size_l1\n",
    "        self.hidden_size_l2 = hidden_size_l2\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embeding_vector_size = embeding_vector_size\n",
    "        ###############################################################################\n",
    "        # Creating placeholders for our input data and expected outputs (target data) #\n",
    "        ###############################################################################\n",
    "        self._input_data = tf.placeholder(tf.int32, [batch_size, num_steps]) #[30#20]\n",
    "        self._targets = tf.placeholder(tf.int32, [batch_size, num_steps]) #[30#20]\n",
    "\n",
    "        ##########################################################################\n",
    "        # Creating the LSTM cell structure and connect it with the RNN structure #\n",
    "        ##########################################################################\n",
    "        # Create the LSTM unit. \n",
    "        # This creates only the structure for the LSTM and has to be associated with a RNN unit still.\n",
    "        # The argument n_hidden(size=200) of BasicLSTMCell is size of hidden layer, that is, the number of hidden units of the LSTM (inside A).\n",
    "        # Size is the same as the size of our hidden layer, and no bias is added to the Forget Gate. \n",
    "        # LSTM cell processes one word at a time and computes probabilities of the possible continuations of the sentence.\n",
    "        lstm_cell_l1 = tf.contrib.rnn.BasicLSTMCell(self.hidden_size_l1, forget_bias=0.0)\n",
    "        lstm_cell_l2 = tf.contrib.rnn.BasicLSTMCell(self.hidden_size_l2, forget_bias=0.0)\n",
    "        \n",
    "        # Unless you changed keep_prob, this won't actually execute -- this is a dropout wrapper for our LSTM unit\n",
    "        # This is an optimization of the LSTM output, but is not needed at all\n",
    "        if action_type == \"is_training\" and keep_prob < 1:\n",
    "            lstm_cell_l1 = tf.contrib.rnn.DropoutWrapper(lstm_cell_l1, output_keep_prob=keep_prob)\n",
    "            lstm_cell_l2 = tf.contrib.rnn.DropoutWrapper(lstm_cell_l2, output_keep_prob=keep_prob)\n",
    "        \n",
    "        # By taking in the LSTM cells as parameters, the MultiRNNCell function junctions the LSTM units to the RNN units.\n",
    "        # RNN cell composed sequentially of multiple simple cells.\n",
    "        stacked_lstm = tf.contrib.rnn.MultiRNNCell([lstm_cell_l1, lstm_cell_l2])\n",
    "\n",
    "        # Define the initial state, i.e., the model state for the very first data point\n",
    "        # It initialize the state of the LSTM memory. The memory state of the network is initialized with a vector of zeros and gets updated after reading each word.\n",
    "        self._initial_state = stacked_lstm.zero_state(batch_size, tf.float32)\n",
    "\n",
    "        ####################################################################\n",
    "        # Creating the word embeddings and pointing them to the input data #\n",
    "        ####################################################################\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            # Create the embeddings for our input data. Size is hidden size.\n",
    "            embedding = tf.get_variable(\"embedding\", [vocab_size, self.embeding_vector_size])  #[10000x200]\n",
    "            # Define where to get the data for our embeddings from\n",
    "            inputs = tf.nn.embedding_lookup(embedding, self._input_data)\n",
    "\n",
    "        # Unless you changed keep_prob, this won't actually execute -- this is a dropout addition for our inputs\n",
    "        # This is an optimization of the input processing and is not needed at all\n",
    "        if action_type == \"is_training\" and keep_prob < 1:\n",
    "            inputs = tf.nn.dropout(inputs, keep_prob)\n",
    "\n",
    "        ############################################\n",
    "        # Creating the input structure for our RNN #\n",
    "        ############################################\n",
    "        # Input structure is 20x[30x200]\n",
    "        # Considering each word is represended by a 200 dimentional vector, and we have 30 batchs, we create 30 word-vectors of size [30xx2000]\n",
    "        # inputs = [tf.squeeze(input_, [1]) for input_ in tf.split(1, num_steps, inputs)]\n",
    "        # The input structure is fed from the embeddings, which are filled in by the input data\n",
    "        # Feeding a batch of b sentences to a RNN:\n",
    "        # In step 1,  first word of each of the b sentences (in a batch) is input in parallel.  \n",
    "        # In step 2,  second word of each of the b sentences is input in parallel. \n",
    "        # The parallelism is only for efficiency.  \n",
    "        # Each sentence in a batch is handled in parallel, but the network sees one word of a sentence at a time and does the computations accordingly. \n",
    "        # All the computations involving the words of all sentences in a batch at a given time step are done in parallel. \n",
    "\n",
    "        ####################################################################################################\n",
    "        # Instantiating our RNN model and retrieving the structure for returning the outputs and the state #\n",
    "        ####################################################################################################\n",
    "        \n",
    "        outputs, state = tf.nn.dynamic_rnn(stacked_lstm, inputs, initial_state=self._initial_state)\n",
    "        #########################################################################\n",
    "        # Creating a logistic unit to return the probability of the output word #\n",
    "        #########################################################################\n",
    "        output = tf.reshape(outputs, [-1, self.hidden_size_l2])\n",
    "        softmax_w = tf.get_variable(\"softmax_w\", [self.hidden_size_l2, vocab_size]) #[200x1000]\n",
    "        softmax_b = tf.get_variable(\"softmax_b\", [vocab_size]) #[1x1000]\n",
    "        logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "        logits = tf.reshape(logits, [self.batch_size, self.num_steps, vocab_size])\n",
    "        prob = tf.nn.softmax(logits)\n",
    "        out_words = tf.argmax(prob, axis=2)\n",
    "        self._output_words = out_words\n",
    "        #########################################################################\n",
    "        # Defining the loss and cost functions for the model's learning to work #\n",
    "        #########################################################################\n",
    "            \n",
    "\n",
    "        # Use the contrib sequence loss and average over the batches\n",
    "        loss = tf.contrib.seq2seq.sequence_loss(\n",
    "            logits,\n",
    "            self.targets,\n",
    "            tf.ones([batch_size, num_steps], dtype=tf.float32),\n",
    "            average_across_timesteps=False,\n",
    "            average_across_batch=True)\n",
    "    \n",
    "#         loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits], [tf.reshape(self._targets, [-1])],\n",
    "#                                                       [tf.ones([batch_size * num_steps])])\n",
    "        self._cost = tf.reduce_sum(loss)\n",
    "\n",
    "        # Store the final state\n",
    "        self._final_state = state\n",
    "\n",
    "        #Everything after this point is relevant only for training\n",
    "        if action_type != \"is_training\":\n",
    "            return\n",
    "\n",
    "        #################################################\n",
    "        # Creating the Training Operation for our Model #\n",
    "        #################################################\n",
    "        # Create a variable for the learning rate\n",
    "        self._lr = tf.Variable(0.0, trainable=False)\n",
    "        # Get all TensorFlow variables marked as \"trainable\" (i.e. all of them except _lr, which we just created)\n",
    "        tvars = tf.trainable_variables()\n",
    "        # Define the gradient clipping threshold\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self._cost, tvars), max_grad_norm)\n",
    "        # Create the gradient descent optimizer with our learning rate\n",
    "        optimizer = tf.train.GradientDescentOptimizer(self.lr)\n",
    "        # Create the training TensorFlow Operation through our optimizer\n",
    "        self._train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "    # Helper functions for our LSTM RNN class\n",
    "\n",
    "    # Assign the learning rate for this model\n",
    "    def assign_lr(self, session, lr_value):\n",
    "        session.run(tf.assign(self.lr, lr_value))\n",
    "\n",
    "    # Returns the input data for this model at a point in time\n",
    "    @property\n",
    "    def input_data(self):\n",
    "        return self._input_data\n",
    "\n",
    "\n",
    "    \n",
    "    # Returns the targets for this model at a point in time\n",
    "    @property\n",
    "    def targets(self):\n",
    "        return self._targets\n",
    "\n",
    "    # Returns the initial state for this model\n",
    "    @property\n",
    "    def initial_state(self):\n",
    "        return self._initial_state\n",
    "\n",
    "    # Returns the defined Cost\n",
    "    @property\n",
    "    def cost(self):\n",
    "        return self._cost\n",
    "\n",
    "    # Returns the final state for this model\n",
    "    @property\n",
    "    def final_state(self):\n",
    "        return self._final_state\n",
    "    \n",
    "    # Returns the final output words for this model\n",
    "    @property\n",
    "    def final_output_words(self):\n",
    "        return self._output_words\n",
    "    \n",
    "    # Returns the current learning rate for this model\n",
    "    @property\n",
    "    def lr(self):\n",
    "        return self._lr\n",
    "\n",
    "    # Returns the training operation defined for this model\n",
    "    @property\n",
    "    def train_op(self):\n",
    "        return self._train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Create the methods to run through time \n",
    "> the <code>run_epoch</code> method to be run at each epoch and a <code>main</code> script which ties all of this together.\n",
    "\n",
    "- What our <code>run_epoch</code> method should do is take our input data and feed it to the relevant operations. This will return at the very least the current result for the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "##########################################################################################################################\n",
    "# run_one_epoch takes as parameters the current session, the model instance, the data to be fed, and the operation to be run #\n",
    "##########################################################################################################################\n",
    "def run_one_epoch(session, m, data, eval_op, verbose=False):\n",
    "\n",
    "    #Define the epoch size based on the length of the data, batch size and the number of steps\n",
    "    epoch_size = ((len(data) // m.batch_size) - 1) // m.num_steps\n",
    "    start_time = time.time()\n",
    "    costs = 0.0\n",
    "    iters = 0\n",
    "\n",
    "    state = session.run(m.initial_state)\n",
    "    \n",
    "    #For each step and data point\n",
    "    for step, (x, y) in enumerate(reader.ptb_iterator(data, m.batch_size, m.num_steps)):\n",
    "        \n",
    "        #Evaluate and return cost, state by running cost, final_state and the function passed as parameter\n",
    "        cost, state, out_words, _ = session.run([m.cost, m.final_state, m.final_output_words, eval_op],\n",
    "                                     {m.input_data: x,\n",
    "                                      m.targets: y,\n",
    "                                      m.initial_state: state})\n",
    "\n",
    "        #Add returned cost to costs (which keeps track of the total costs for this epoch)\n",
    "        costs += cost\n",
    "        \n",
    "        #Add number of steps to iteration counter\n",
    "        iters += m.num_steps\n",
    "\n",
    "        if verbose and step % (epoch_size // 10) == 10:\n",
    "            print(f\"Itr {step} of {epoch_size}, perplexity: {np.exp(costs / iters):.3f} speed: {iters * m.batch_size / (time.time() - start_time):.0f} wps\")\n",
    "\n",
    "    # Returns the Perplexity rating for us to keep track of how the model is evolving\n",
    "    return np.exp(costs / iters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Create the <code>main</code> method to tie everything together\n",
    ">The code here reads the data from the directory, using the <code>reader</code> helper module, and then trains and evaluates the model on both a testing and a validating subset of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Reads the data and separates it into training data, validation data and testing data\n",
    "raw_data = reader.ptb_raw_data(data_dir)\n",
    "train_data, valid_data, test_data, _, _ = raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Initializes the Execution Graph and the Session\n",
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    initializer = tf.random_uniform_initializer(-init_scale, init_scale)\n",
    "    \n",
    "    # Instantiates the model for training\n",
    "    # tf.variable_scope add a prefix to the variables created with tf.get_variable\n",
    "    with tf.variable_scope(\"model\", reuse=None, initializer=initializer):\n",
    "        m = PTBModel(\"is_training\")\n",
    "        \n",
    "    # Reuses the trained parameters for the validation and testing models\n",
    "    # They are different instances but use the same variables for weights and biases, they just don't change when data is input\n",
    "    with tf.variable_scope(\"model\", reuse=True, initializer=initializer):\n",
    "        mvalid = PTBModel(\"is_validating\")\n",
    "        mtest = PTBModel(\"is_testing\")\n",
    "\n",
    "    #Initialize all variables\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    for i in range(max_epoch):\n",
    "        # Define the decay for this epoch\n",
    "        lr_decay = decay ** max(i - max_epoch_decay_lr, 0.0)\n",
    "        \n",
    "        # Set the decayed learning rate as the learning rate for this epoch\n",
    "        m.assign_lr(session, learning_rate * lr_decay)\n",
    "\n",
    "        print(f\"Epoch {i + 1} : Learning rate: {session.run(m.lr):.3f}\" )\n",
    "        \n",
    "        # Run the loop for this epoch in the training model\n",
    "        train_perplexity = run_one_epoch(session, m, train_data, m.train_op, verbose=True)\n",
    "        print(f\"Epoch {i + 1} : Train Perplexity: {train_perplexity:.3f}\")\n",
    "        \n",
    "        # Run the loop for this epoch in the validation model\n",
    "        valid_perplexity = run_one_epoch(session, mvalid, valid_data, tf.no_op())\n",
    "        print(f\"Epoch {i + 1} : Valid Perplexity: {valid_perplexity:.3f}\")\n",
    "    \n",
    "    # Run the loop in the testing model to see how effective was our training\n",
    "    test_perplexity = run_one_epoch(session, mtest, test_data, tf.no_op())\n",
    "    \n",
    "    print(f\"Test Perplexity: {test_perplexity:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1 : Learning rate: 1.000\n",
    "# Itr 10 of 774, perplexity: 4034.922 speed: 1354 wps\n",
    "# Itr 87 of 774, perplexity: 1255.013 speed: 2294 wps\n",
    "# Itr 164 of 774, perplexity: 976.759 speed: 2564 wps\n",
    "# Itr 241 of 774, perplexity: 819.611 speed: 2671 wps\n",
    "# Itr 318 of 774, perplexity: 726.925 speed: 2689 wps\n",
    "# Itr 395 of 774, perplexity: 650.184 speed: 2747 wps\n",
    "# Itr 472 of 774, perplexity: 590.447 speed: 2760 wps\n",
    "# Itr 549 of 774, perplexity: 537.357 speed: 2800 wps\n",
    "# Itr 626 of 774, perplexity: 494.092 speed: 2782 wps\n",
    "# Itr 703 of 774, perplexity: 459.832 speed: 2779 wps\n",
    "# Epoch 1 : Train Perplexity: 435.117\n",
    "# Epoch 1 : Valid Perplexity: 258.920\n",
    "# Epoch 2 : Learning rate: 1.000\n",
    "# Itr 10 of 774, perplexity: 278.594 speed: 2302 wps\n",
    "# Itr 87 of 774, perplexity: 240.389 speed: 2714 wps\n",
    "# Itr 164 of 774, perplexity: 230.370 speed: 2641 wps\n",
    "# Itr 241 of 774, perplexity: 221.183 speed: 2379 wps\n",
    "# Itr 318 of 774, perplexity: 218.418 speed: 2497 wps\n",
    "# Itr 395 of 774, perplexity: 212.218 speed: 2579 wps\n",
    "# Itr 472 of 774, perplexity: 207.639 speed: 2634 wps\n",
    "# Itr 549 of 774, perplexity: 200.778 speed: 2680 wps\n",
    "# Itr 626 of 774, perplexity: 195.110 speed: 2716 wps\n",
    "# Itr 703 of 774, perplexity: 190.749 speed: 2739 wps\n",
    "# Epoch 2 : Train Perplexity: 187.855\n",
    "# Epoch 2 : Valid Perplexity: 174.740\n",
    "# Epoch 3 : Learning rate: 1.000\n",
    "# Itr 10 of 774, perplexity: 186.172 speed: 2986 wps\n",
    "# Itr 87 of 774, perplexity: 159.186 speed: 2940 wps\n",
    "# Itr 164 of 774, perplexity: 155.778 speed: 2898 wps\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The model's perplexity rating drops very quickly after a few iterations. \n",
    "As was elaborated before, <b>lower Perplexity means that the model is more certain about its prediction</b>. As such, we can be sure that this model is performing well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation using RNN/LSTM (Character-level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">implements a Recurrent Neural Network with LSTM/RNN units for training/sampling from character-level language models. \n",
    "\n",
    "- In other words, the model takes a text file as input and trains the RNN network that learns to predict the next character in a sequence.  \n",
    "- The RNN can then be used to generate text character by character that will look like the original training data. \n",
    "\n",
    ">This code is based on this [blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), and the code is an step-by-step implimentation of the [character-level implimentation](https://github.com/crazydonkey200/tensorflow-char-rnn).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the requiered libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import codecs\n",
    "import os\n",
    "import collections\n",
    "from six.moves import cPickle\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader\n",
    "The following cell is a class that help to read data from input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLoader():\n",
    "    def __init__(self, data_dir, batch_size, seq_length, encoding='utf-8'):\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_length = seq_length\n",
    "        self.encoding = encoding\n",
    "\n",
    "        input_file = os.path.join(data_dir, \"input.txt\")\n",
    "        vocab_file = os.path.join(data_dir, \"vocab.pkl\")\n",
    "        tensor_file = os.path.join(data_dir, \"data.npy\")\n",
    "\n",
    "        if not (os.path.exists(vocab_file) and os.path.exists(tensor_file)):\n",
    "            print(\"reading text file\")\n",
    "            self.preprocess(input_file, vocab_file, tensor_file)\n",
    "        else:\n",
    "            print(\"loading preprocessed files\")\n",
    "            self.load_preprocessed(vocab_file, tensor_file)\n",
    "        self.create_batches()\n",
    "        self.reset_batch_pointer()\n",
    "\n",
    "    def preprocess(self, input_file, vocab_file, tensor_file):\n",
    "        with codecs.open(input_file, \"r\", encoding=self.encoding) as f:\n",
    "            data = f.read()\n",
    "        counter = collections.Counter(data)\n",
    "        count_pairs = sorted(counter.items(), key=lambda x: -x[1])\n",
    "        self.chars, _ = zip(*count_pairs)\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.vocab = dict(zip(self.chars, range(len(self.chars))))\n",
    "        with open(vocab_file, 'wb') as f:\n",
    "            cPickle.dump(self.chars, f)\n",
    "        self.tensor = np.array(list(map(self.vocab.get, data)))\n",
    "        np.save(tensor_file, self.tensor)\n",
    "\n",
    "    def load_preprocessed(self, vocab_file, tensor_file):\n",
    "        with open(vocab_file, 'rb') as f:\n",
    "            self.chars = cPickle.load(f)\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.vocab = dict(zip(self.chars, range(len(self.chars))))\n",
    "        self.tensor = np.load(tensor_file)\n",
    "        self.num_batches = int(self.tensor.size / (self.batch_size * self.seq_length))\n",
    "\n",
    "    def create_batches(self):\n",
    "        self.num_batches = int(self.tensor.size / (self.batch_size * self.seq_length))\n",
    "\n",
    "        # When the data (tensor) is too small, let's give them a better error message\n",
    "        if self.num_batches==0:\n",
    "            assert False, \"Not enough data. Make seq_length and batch_size small.\"\n",
    "\n",
    "        self.tensor = self.tensor[:self.num_batches * self.batch_size * self.seq_length]\n",
    "        xdata = self.tensor\n",
    "        ydata = np.copy(self.tensor)\n",
    "        ydata[:-1] = xdata[1:]\n",
    "        ydata[-1] = xdata[0]\n",
    "        self.x_batches = np.split(xdata.reshape(self.batch_size, -1), self.num_batches, 1)\n",
    "        self.y_batches = np.split(ydata.reshape(self.batch_size, -1), self.num_batches, 1)\n",
    "\n",
    "\n",
    "    def next_batch(self):\n",
    "        x, y = self.x_batches[self.pointer], self.y_batches[self.pointer]\n",
    "        self.pointer += 1\n",
    "        return x, y\n",
    "\n",
    "    def reset_batch_pointer(self):\n",
    "        self.pointer = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "#### Batch, number_of_batch, batch_size and seq_length\n",
    "what is batch, number_of_batch, batch_size and seq_length in the charcter level example?  \n",
    "\n",
    "Lets assume the input is this sentence: '__here is an example__'. Then:\n",
    "- txt_length = 18  \n",
    "- seq_length = 3  \n",
    "- batch_size = 2  \n",
    "- number_of_batchs = 18/3*2 = 3\n",
    "- batch = array (['h','e','r'],['e',' ','i'])\n",
    "- sample Seq = 'her'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now, lets look at a real dataset, with real parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 50 # RNN sequence length\n",
    "batch_size = 60  # minibatch size, i.e. size of data in each epoch\n",
    "num_epochs = 125 # you should change it to 50 if you want to see a relatively good results\n",
    "learning_rate = 0.002\n",
    "decay_rate = 0.97\n",
    "rnn_size = 128 # size of RNN hidden state (output dimension)\n",
    "num_layers = 2 #number of layers in the RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download the input file, and print a part of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nv -O ../data/input.txt https://ibm.box.com/shared/static/a3f9e9mbpup09toq35ut7ke3l3lf03hg.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-27 11:22:13 URL:https://public.boxcloud.com/d/1/b1!UdW5A5bRfXRMpSOOxObNFYiL-9Fgfmc2XV5r6MkBu3wHIbUdpQS2OjqlaDYgL5F9b-WeDPpNfuTrmxM3-ARJObfEfIQL7-tNY07r-iZ2ukyXIX1OlibZCmBA8HmY9a7Ziqzoyriia4caTR87CgF1BmfmAB85cSII8aL41KNpWlsAzQduqH3k9Qrc0A_DuQQbIs3Gje9coCBOZx6scK43W4em4rDAQU_7xFleILBRe64pXCQJlok7XsLPGRkITpSRFbpjUHAxrXOw8Z1Y2id2iYPX1TNG-BUySGoZ_2BT3DFRpulIZ67kvLs-4pqb4RnI9YubCYTmSuZvpjMHlc0fsaMpOTNmIPR5qL6GF4ohO9mlPtHMipRp6kA4JDehL8bYY_WFY49KYMrG4nBfigT81VFA6ntsifBpgK_S36nvccR6cSj9kU-3PJ_Xu0TosgpMXEHh2jIRG8v4B9kKyy-AOiM5_llQFmaBhHnByQ93fMVx-ryLswx4W0_1sx60kldb9-roTv8p8E73_LpMTmQSkawKGGMyBUDh5GjXE7OBBOZUZPOJvTMaZqwjI0p8zLMYUufZ6Sasz3q-QxDwsiwDE0QUXToMIwxSFD4urea0fawwtW9RbQpoZJsqg5j4cGcBQoEQs-Z5xYWDW4LO4c-VHD84KTL0HH1AEG7xqY4HFoCNM6BqCGwZ29jiwgod5vwNLNzzt44qLZSgq39SZPuq11F3XM-Il-QQXMHSafihI3oFDJjXHaSopIrEv6qDutR2TwXIIuATlL5RJRquOB3g2j60jxYS8F6CeOplbOMIwq_wBXbIa0uRRKNMPtqaf78eKvZbQUWJMuEzUCP9c1oGNmD4ZOR4omlljFxnEyId835iWS0F7pkIUS4Vx5R1euKHCGZ0o5I42hv_W0oLBBXotn8UyAmf43oUrh88Z0Fwx6Fopx8BvWqZv4wXusNVIMKaVXoG1lfx2FtTGiROFSqVHnaQYbDjTCYtkhwEdwqLg6pNEWTVRVHGv_8eCcyEHjux77d75hhsRUAR28gLHbksZHDVV_U4lYmiaPNsGhDMZ_pmOGX0eSzSZMdX0JE_l90MlPDtkgLKgo4qrhxRiOTJwxt-qvf3tIDBIUUmsWgX9tlMe-QICzDXK42-2iJtsSRsI6KVlqp-C6peOif1ruX5STUL-63ZSDm7O8xHWmM9xwjpaOd-jA7PZ0QszdU73Pu08uFKh20iuAlypefNombwzLSYFsxwvEK3W3_2TvcLO5um0QTdPrXpHvILs-yPYedz_HYA2aZbmrNtORqyW6AIevio30Ufqzraz6SLL2fenO5NQ0VTZLCAHdZN_YNpMZZHp8gZPlpbDLXyJzwzfZZjbnjDy9rWptiaYJCX6d3oixdoAYNdo5NVfRnU2lH7HXY5iFmVdzi0AHV5wYtGMV9FTJq8strgfRCPo3FJ3f3ntEE./download [1115393/1115393] -> \"../data/input.txt\" [1]\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/input.txt', 'r') as f:\n",
    "    read_data = f.read()\n",
    "    print (read_data[0:100])\n",
    "f.closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can read the data at batches using the __TextLoader__ class. It will convert the characters to numbers, and represent each sequence as a vector in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading text file\n",
      "vocabulary size: 65\n",
      "Characters: (' ', 'e', 't', 'o', 'a', 'h', 's', 'r', 'n', 'i', '\\n', 'l', 'd', 'u', 'm', 'y', ',', 'w', 'f', 'c', 'g', 'I', 'b', 'p', ':', '.', 'A', 'v', 'k', 'T', \"'\", 'E', 'O', 'N', 'R', 'S', 'L', 'C', ';', 'W', 'U', 'H', 'M', 'B', '?', 'G', '!', 'D', '-', 'F', 'Y', 'P', 'K', 'V', 'j', 'q', 'x', 'z', 'J', 'Q', 'Z', 'X', '3', '&', '$')\n",
      "vocab number of 'F': 49\n",
      "Character sequences (first batch): [[49  9  7 ...  1  4  7]\n",
      " [19  4 14 ... 14  9 20]\n",
      " [ 8 20 10 ...  8 10 18]\n",
      " ...\n",
      " [21  2  0 ...  0 21  0]\n",
      " [ 9  7  7 ...  0  2  3]\n",
      " [ 3  7  0 ...  5  9 23]]\n"
     ]
    }
   ],
   "source": [
    "data_loader = TextLoader('../data/', batch_size, seq_length)\n",
    "vocab_size = data_loader.vocab_size\n",
    "print (\"vocabulary size:\" ,data_loader.vocab_size)\n",
    "print (\"Characters:\" ,data_loader.chars)\n",
    "print (\"vocab number of 'F':\",data_loader.vocab['F'])\n",
    "print (\"Character sequences (first batch):\", data_loader.x_batches[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  9,  7, ...,  1,  4,  7],\n",
       "       [19,  4, 14, ..., 14,  9, 20],\n",
       "       [ 8, 20, 10, ...,  8, 10, 18],\n",
       "       ...,\n",
       "       [21,  2,  0, ...,  0, 21,  0],\n",
       "       [ 9,  7,  7, ...,  0,  2,  3],\n",
       "       [ 3,  7,  0, ...,  5,  9, 23]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = data_loader.next_batch()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 50)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape  #batch_size =60, seq_length=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, __y__ is the next character for each character in __x__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  7,  6, ...,  4,  7,  0],\n",
       "       [ 4, 14, 22, ...,  9, 20,  5],\n",
       "       [20, 10, 29, ..., 10, 18,  4],\n",
       "       ...,\n",
       "       [ 2,  0,  6, ..., 21,  0,  6],\n",
       "       [ 7,  7,  4, ...,  2,  3,  0],\n",
       "       [ 7,  0, 33, ...,  9, 23,  0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Architecture\n",
    "Each LSTM cell has 5 parts:\n",
    "1. Input\n",
    "2. prv_state\n",
    "3. prv_output\n",
    "4. new_state\n",
    "5. new_output\n",
    "\n",
    "\n",
    "- Each LSTM cell has an input layre, which its size is 128 units in our case. The input vector's dimension also is 128, which is the dimensionality of embedding vector, so called, dimension size of W2V/embedding, for each character/word.\n",
    "- Each LSTM cell has a hidden layer, where there are some hidden units. The argument n_hidden=128 of BasicLSTMCell is the number of hidden units of the LSTM (inside A). It keeps the size of the output and state vector. It is also known as, rnn_size, num_units, num_hidden_units, and LSTM size\n",
    "- An LSTM keeps two pieces of information as it propagates through time: \n",
    "    - __hidden state__ vector: Each LSTM cell accept a vector, called __hidden state__ vector, of size n_hidden=128, and its value is returned to the LSTM cell in the next step. The __hidden state__ vector; which is the memory of the LSTM, accumulates using its (forget, input, and output) gates through time. \"num_units\" is equivalant to \"size of RNN hidden state\". number of hidden units is the dimensianality of the output (= dimesianality of the state) of the LSTM cell.\n",
    "    - __previous time-step output__: For each LSTM cell that we initialize, we need to supply a value (128 in this case) for the hidden dimension, or as some people like to call it, the number of units in the LSTM cell. \n",
    "\n",
    "\n",
    "#### num_layers = 2 \n",
    "- number of layers in the RNN, is defined by num_layers\n",
    "- An input of MultiRNNCell is __cells__ which is list of RNNCells that will be composed in this order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining stacked RNN Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BasicRNNCell__ is the most basic RNN cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-77-cbc7d8d66937>:1: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "cell = tf.contrib.rnn.BasicRNNCell(rnn_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n"
     ]
    }
   ],
   "source": [
    "# a two layer cell\n",
    "stacked_cell = tf.contrib.rnn.MultiRNNCell([cell] * num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hidden state size\n",
    "stacked_cell.output_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__state__ varibale keeps output and new_state of the LSTM, so it is a touple of size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_cell.state_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_5:0' shape=(60, 50) dtype=int32>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = tf.placeholder(tf.int32, [batch_size, seq_length])# a 60x50\n",
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and target data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_6:0' shape=(60, 50) dtype=int32>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = tf.placeholder(tf.int32, [batch_size, seq_length]) # a 60x50\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory state of the network is initialized with a vector of zeros and gets updated after reading each character.\n",
    "\n",
    "__BasicRNNCell.zero_state(batch_size, dtype)__ Return zero-filled state tensor(s). In this function, batch_size\n",
    "representing the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = stacked_cell.zero_state(batch_size, tf.float32) #why batch_size ? 60x128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check the value of the input_data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49,  9,  7, ...,  1,  4,  7],\n",
       "       [19,  4, 14, ..., 14,  9, 20],\n",
       "       [ 8, 20, 10, ...,  8, 10, 18],\n",
       "       ...,\n",
       "       [21,  2,  0, ...,  0, 21,  0],\n",
       "       [ 9,  7,  7, ...,  0,  2,  3],\n",
       "       [ 3,  7,  0, ...,  5,  9, 23]], dtype=int32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "feed_dict={input_data:x, targets:y}\n",
    "session.run(input_data, feed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding\n",
    "In this section, we build a 128-dim vector for each character. As we have 60 batches, and 50 character in each sequence, it will generate a [60,50,128] matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notice:__ The function `tf.get_variable()` is used to share a variable and to initialize it in one place. `tf.get_variable()` is used to get or create a variable instead of a direct call to `tf.Variable`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('rnnlm', reuse=False):\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size]) #128x65\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [vocab_size]) # 1x65)\n",
    "    #with tf.device(\"/cpu:0\"):\n",
    "        \n",
    "    # embedding variable is initialized randomely\n",
    "    embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size])  #65x128\n",
    "\n",
    "    # embedding_lookup goes to each row of input_data, and for each character in the row, finds the correspond vector in embedding\n",
    "    # it creates a 60*50*[1*128] matrix\n",
    "    # so, the first elemnt of em, is a matrix of 50x128, which each row of it is vector representing that character\n",
    "    em = tf.nn.embedding_lookup(embedding, input_data) # em is 60x50x[1*128]\n",
    "    # split: Splits a tensor into sub tensors.\n",
    "    # syntax:  tf.split(split_dim, num_split, value, name='split')\n",
    "    # it will split the 60x50x[1x128] matrix into 50 matrix of 60x[1*128]\n",
    "    inputs = tf.split(em, seq_length, 1)\n",
    "    # It will convert the list to 50 matrix of [60x128]\n",
    "    inputs = [tf.squeeze(input_, [1]) for input_ in inputs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the __embedding__, __em__, and __inputs__ variabbles:\n",
    "\n",
    "Embedding variable is initialized with random values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10606678, -0.10996144, -0.00652313, ...,  0.01547419,\n",
       "         0.17575805,  0.04906286],\n",
       "       [-0.14983882,  0.08913983, -0.00450294, ...,  0.03476331,\n",
       "         0.11869954,  0.1440006 ],\n",
       "       [ 0.13216461,  0.15371437,  0.16808923, ..., -0.04437257,\n",
       "        -0.03265285, -0.00283989],\n",
       "       ...,\n",
       "       [ 0.10224696,  0.10813625,  0.17569385, ...,  0.05461036,\n",
       "         0.141338  ,  0.13294958],\n",
       "       [ 0.09353928, -0.01787746, -0.04660253, ...,  0.12788205,\n",
       "         0.00634539,  0.16024141],\n",
       "       [-0.0592452 , -0.09775198,  0.09643699, ...,  0.095843  ,\n",
       "        -0.08621966, -0.03257227]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "#print embedding.shape\n",
    "session.run(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first elemnt of em, is a matrix of 50x128, which each row of it is vector representing that character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 50, 128)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.0518547 ,  0.12397622, -0.16920407, ...,  0.05532134,\n",
       "        -0.09239107, -0.06787327],\n",
       "       [-0.15762489, -0.07445458,  0.16105498, ...,  0.1600024 ,\n",
       "         0.07966201,  0.0433673 ],\n",
       "       [-0.13110736,  0.15457936,  0.02260895, ...,  0.02942652,\n",
       "         0.15372624,  0.15432565],\n",
       "       ...,\n",
       "       [-0.14983882,  0.08913983, -0.00450294, ...,  0.03476331,\n",
       "         0.11869954,  0.1440006 ],\n",
       "       [ 0.04557078, -0.06591516,  0.00861327, ...,  0.00207677,\n",
       "        -0.13221681,  0.09018792],\n",
       "       [-0.13110736,  0.15457936,  0.02260895, ...,  0.02942652,\n",
       "         0.15372624,  0.15432565]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = tf.nn.embedding_lookup(embedding, input_data)\n",
    "emp = session.run(em,feed_dict={input_data:x})\n",
    "print (emp.shape)\n",
    "emp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider each sequence as a sentence of length 50 characters, then, the first item in __inputs__ is a [60x128] vector which represents the first characters of 60 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Squeeze:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'Squeeze_1:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'Squeeze_2:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'Squeeze_3:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'Squeeze_4:0' shape=(60, 128) dtype=float32>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.split(em, seq_length, 1)\n",
    "inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "inputs[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding a batch of 50 sequence to a RNN:\n",
    "\n",
    "The feeding process for iputs is as following:\n",
    "\n",
    "- Step 1:  first character of each of the 50 sentences (in a batch) is entered in parallel.  \n",
    "- Step 2:  second character of each of the 50 sentences is input in parallel. \n",
    "- Step n: nth character of each of the 50 sentences is input in parallel.  \n",
    "\n",
    "The parallelism is only for efficiency.  Each character in a batch is handled in parallel,  but the network sees one character of a sequence at a time and does the computations accordingly. All the computations involving the characters of all sequences in a batch at a given time step are done in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0518547 ,  0.12397622, -0.16920407, ...,  0.05532134,\n",
       "        -0.09239107, -0.06787327],\n",
       "       [-0.14458391,  0.17019002,  0.07491867, ...,  0.14642338,\n",
       "         0.02281229, -0.07385635],\n",
       "       [-0.14994937,  0.00373062,  0.08041666, ...,  0.05768774,\n",
       "        -0.14338623,  0.00741605],\n",
       "       ...,\n",
       "       [ 0.08130963, -0.07729489,  0.11279018, ...,  0.04599568,\n",
       "         0.159716  , -0.05065273],\n",
       "       [-0.15762489, -0.07445458,  0.16105498, ...,  0.1600024 ,\n",
       "         0.07966201,  0.0433673 ],\n",
       "       [ 0.0257075 , -0.06409662, -0.03194405, ...,  0.10057653,\n",
       "         0.00797263,  0.01868001]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(inputs[0],feed_dict={input_data:x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feeding the RNN with one batch, we can check the new output and new state of network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_98:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_99:0' shape=(60, 128) dtype=float32>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outputs is 50x[60*128]\n",
    "outputs, new_state = tf.contrib.legacy_seq2seq.rnn_decoder(inputs, initial_state, stacked_cell, loop_function=None, scope='rnnlm')\n",
    "new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_1:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_3:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_5:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_7:0' shape=(60, 128) dtype=float32>,\n",
       " <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/Tanh_9:0' shape=(60, 128) dtype=float32>]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the output of network after feeding it with first batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03045642,  0.02001984,  0.04574184, ..., -0.09082884,\n",
       "        -0.02112878,  0.01364688],\n",
       "       [ 0.05173488,  0.06454567, -0.03036163, ..., -0.13066103,\n",
       "         0.01971627, -0.0071872 ],\n",
       "       [-0.05427434,  0.04849094, -0.0386098 , ...,  0.11250032,\n",
       "        -0.18134393, -0.00103781],\n",
       "       ...,\n",
       "       [-0.063368  ,  0.06625741, -0.05667046, ...,  0.13456039,\n",
       "         0.21285625, -0.01841194],\n",
       "       [-0.07623049,  0.14171883, -0.01260086, ...,  0.0381349 ,\n",
       "         0.007086  , -0.08626648],\n",
       "       [ 0.08212979, -0.05736017, -0.01186307, ...,  0.06533887,\n",
       "        -0.0380859 ,  0.0499438 ]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_output = outputs[0]\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(first_output,feed_dict={input_data:x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was explained, __outputs__ variable is a 50x[60x128] tensor. We need to reshape it back to [60x50x128] to be able to calculate the probablity of the next character using the softmax. The __softmax_w__ shape is [rnn_size, vocab_size],whihc is [128x65] in our case. Threfore, we have a fully connected layer on top of LSTM cells, which help us to decode the next charachter. We can use the __softmax(output * softmax_w + softmax_b)__ for this purpose. The shape of the matrixis would be:\n",
    "\n",
    "softmax([60x50x128]x[128x65]+[1x65]) = [60x50x65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do it step-by-step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_2:0' shape=(3000, 128) dtype=float32>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tf.reshape(tf.concat( outputs,1), [-1, rnn_size])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_2:0' shape=(3000, 65) dtype=float32>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax_1:0' shape=(3000, 65) dtype=float32>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = tf.nn.softmax(logits)\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the probablity of the next chracter in all batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0165848 , 0.01659987, 0.01325537, ..., 0.01900977, 0.01372861,\n",
       "        0.01266062],\n",
       "       [0.01599846, 0.01477488, 0.01219108, ..., 0.01822607, 0.01411264,\n",
       "        0.01267828],\n",
       "       [0.01437985, 0.01738792, 0.01427173, ..., 0.01385782, 0.0130742 ,\n",
       "        0.01281966],\n",
       "       ...,\n",
       "       [0.02350089, 0.0106464 , 0.01902394, ..., 0.02112582, 0.01120728,\n",
       "        0.01416604],\n",
       "       [0.01573915, 0.02049532, 0.01013148, ..., 0.01873042, 0.01556396,\n",
       "        0.01006579],\n",
       "       [0.01771649, 0.01220501, 0.01579605, ..., 0.01247389, 0.01057662,\n",
       "        0.01140283]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(tf.global_variables_initializer())\n",
    "session.run(probs,feed_dict={input_data:x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are in the position to calculate the cost of training with __loss function__, and keep feedng the network to learn it. But, the question is: what the LSTM networks learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'LSTM_sample1/basic_lstm_cell/kernel:0' shape=(10, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'LSTM_sample1/basic_lstm_cell/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0' shape=(10, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0' shape=(9, 20) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0' shape=(20,) dtype=float32_ref>,\n",
       " <tf.Variable 'embedding_vocab:0' shape=(10000, 200) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0' shape=(456, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0' shape=(384, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'softmax_w:0' shape=(128, 10000) dtype=float32_ref>,\n",
       " <tf.Variable 'softmax_b:0' shape=(10000,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/softmax_w:0' shape=(128, 65) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/softmax_b:0' shape=(65,) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/embedding:0' shape=(65, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/kernel:0' shape=(256, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/bias:0' shape=(128,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_clip =5.\n",
    "tvars = tf.trainable_variables()\n",
    "tvars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All together\n",
    "Now, let's put all of parts together in a class, and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel():\n",
    "    def __init__(self,sample=False):\n",
    "        rnn_size = 128 # size of RNN hidden state vector\n",
    "        batch_size = 60 # minibatch size, i.e. size of dataset in each epoch\n",
    "        seq_length = 50 # RNN sequence length\n",
    "        num_layers = 2 # number of layers in the RNN\n",
    "        vocab_size = 65\n",
    "        grad_clip = 5.\n",
    "        if sample:\n",
    "            print(\">> sample mode:\")\n",
    "            batch_size = 1\n",
    "            seq_length = 1\n",
    "        # The core of the model consists of an LSTM cell that processes one char at a time and computes probabilities of the possible continuations of the char. \n",
    "        basic_cell = tf.contrib.rnn.BasicRNNCell(rnn_size)\n",
    "        # model.cell.state_size is (128, 128)\n",
    "        self.stacked_cell = tf.contrib.rnn.MultiRNNCell([basic_cell] * num_layers)\n",
    "\n",
    "        self.input_data = tf.placeholder(tf.int32, [batch_size, seq_length], name=\"input_data\")\n",
    "        self.targets = tf.placeholder(tf.int32, [batch_size, seq_length], name=\"targets\")\n",
    "        # Initial state of the LSTM memory.\n",
    "        # The memory state of the network is initialized with a vector of zeros and gets updated after reading each char. \n",
    "        self.initial_state = stacked_cell.zero_state(batch_size, tf.float32) #why batch_size\n",
    "\n",
    "        with tf.variable_scope('rnnlm_class1'):\n",
    "            softmax_w = tf.get_variable(\"softmax_w\", [rnn_size, vocab_size]) #128x65\n",
    "            softmax_b = tf.get_variable(\"softmax_b\", [vocab_size]) # 1x65\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size])  #65x128\n",
    "                inputs = tf.split(tf.nn.embedding_lookup(embedding, self.input_data), seq_length, 1)\n",
    "                inputs = [tf.squeeze(input_, [1]) for input_ in inputs]\n",
    "                #inputs = tf.split(em, seq_length, 1)\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "        # The value of state is updated after processing each batch of chars.\n",
    "        outputs, last_state = tf.contrib.legacy_seq2seq.rnn_decoder(inputs, self.initial_state, self.stacked_cell, loop_function=None, scope='rnnlm_class1')\n",
    "        output = tf.reshape(tf.concat(outputs,1), [-1, rnn_size])\n",
    "        self.logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "        self.probs = tf.nn.softmax(self.logits)\n",
    "        loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([self.logits],\n",
    "                [tf.reshape(self.targets, [-1])],\n",
    "                [tf.ones([batch_size * seq_length])],\n",
    "                vocab_size)\n",
    "        self.cost = tf.reduce_sum(loss) / batch_size / seq_length\n",
    "        self.final_state = last_state\n",
    "        self.lr = tf.Variable(0.0, trainable=False)\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars),grad_clip)\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    \n",
    "    def sample(self, sess, chars, vocab, num=200, prime='The ', sampling_type=1):\n",
    "        state = sess.run(self.stacked_cell.zero_state(1, tf.float32))\n",
    "        #print state\n",
    "        for char in prime[:-1]:\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0, 0] = vocab[char]\n",
    "            feed = {self.input_data: x, self.initial_state:state}\n",
    "            [state] = sess.run([self.final_state], feed)\n",
    "\n",
    "        def weighted_pick(weights):\n",
    "            t = np.cumsum(weights)\n",
    "            s = np.sum(weights)\n",
    "            return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "        ret = prime\n",
    "        char = prime[-1]\n",
    "        for n in range(num):\n",
    "            x = np.zeros((1, 1))\n",
    "            x[0, 0] = vocab[char]\n",
    "            feed = {self.input_data: x, self.initial_state:state}\n",
    "            [probs, state] = sess.run([self.probs, self.final_state], feed)\n",
    "            p = probs[0]\n",
    "\n",
    "            if sampling_type == 0:\n",
    "                sample = np.argmax(p)\n",
    "            elif sampling_type == 2:\n",
    "                if char == ' ':\n",
    "                    sample = weighted_pick(p)\n",
    "                else:\n",
    "                    sample = np.argmax(p)\n",
    "            else: # sampling_type == 1 default:\n",
    "                sample = weighted_pick(p)\n",
    "\n",
    "            pred = chars[sample]\n",
    "            ret += pred\n",
    "            char = pred\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LSTM object\n",
    "Now we create a LSTM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"rnn\"):\n",
    "    model = LSTMModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train usinng LSTMModel class\n",
    "We can train our model through feeding batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for e in range(num_epochs): # num_epochs is 5 for test, but should be higher\n",
    "        sess.run(tf.assign(model.lr, learning_rate * (decay_rate ** e)))\n",
    "        data_loader.reset_batch_pointer()\n",
    "        state = sess.run(model.initial_state) # (2x[60x128])\n",
    "        for b in range(data_loader.num_batches): #for each batch\n",
    "            start = time.time()\n",
    "            x, y = data_loader.next_batch()\n",
    "            feed = {model.input_data: x, model.targets: y, model.initial_state:state}\n",
    "            train_loss, state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\n",
    "            end = time.time()\n",
    "        print(f\"{e * data_loader.num_batches + b}/{ num_epochs * data_loader.num_batches} epoch {e}, \\\n",
    "                train_loss = {train_loss:.3f}, \\\n",
    "                time/batch = {end - start:.3f}\")\n",
    "        with tf.variable_scope(\"rnn\", reuse=True):\n",
    "            sample_model = LSTMModel(sample=True)\n",
    "            print (sample_model.sample(sess, data_loader.chars , data_loader.vocab, num=50, prime='The ', sampling_type=1))\n",
    "            print ('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 370/46375 epoch 0,                 train_loss = 1.920,                 time/batch = 0.075\n",
    "# >> sample mode:\n",
    "# The with he you allied doner!\n",
    "\n",
    "# Shamn wele chy hie.\n",
    "\n",
    "# NI\n",
    "# ----------------------------------\n",
    "# 741/46375 epoch 1,                 train_loss = 1.756,                 time/batch = 0.083\n",
    "# >> sample mode:\n",
    "# The rate.\n",
    "# And have a dode\n",
    "# You, time us busitied, gao, \n",
    "# ----------------------------------\n",
    "# 1112/46375 epoch 2,                 train_loss = 1.678,                 time/batch = 0.068\n",
    "# >> sample mode:\n",
    "# The of all of spose, all ady than where's you another \n",
    "# ----------------------------------\n",
    "# 1483/46375 epoch 3,                 train_loss = 1.632,                 time/batch = 0.079\n",
    "# >> sample mode:\n",
    "# The plous-\n",
    "# How woment Do none.\n",
    "\n",
    "# DUKE ONENES:\n",
    "# And me.\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# 1854/46375 epoch 4,                 train_loss = 1.606,                 time/batch = 0.083\n",
    "# >> sample mode:\n",
    "# The renger's\n",
    "# iple, to at that is spirest\n",
    "# And not so ma\n",
    "# ----------------------------------\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence classification with LSTM on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Recurrent Neural Networks are Deep Learning models with simple structures and a feedback mechanism builted-in\n",
    "- the output of a layer is added to the next input and fed back to the same layer.\n",
    "\n",
    "The Recurrent Neural Network is a specialized type of Neural Network that solves the issue of **maintaining context for Sequential data** -- such as Weather data, Stocks, Genes, etc. \n",
    "- At each iterative step, the processing unit takes in an input and the current state of the network, and produces an output and a new state that is **re-fed into the network**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**this model has some problems**. \n",
    "- It's very computationally expensive to maintain the state for a large amount of units, even more so over a long amount of time.\n",
    "- Recurrent Networks are very sensitive to changes in their parameters. \n",
    "- As such, they are prone to different problems with their Gradient Descent optimizer -- they either grow exponentially (Exploding Gradient) or drop down to near zero and stabilize (Vanishing Gradient), both problems that greatly harm a model's learning capability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Solve the oversensitivity to parameter changes, i.e., make backpropagating through the Recurrent Networks more viable.\n",
    "- Cover only LSTM and its implementation using TensorFlow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## <a id=\"arch\"/>Architectures\n",
    "- Fully Recurrent Network\n",
    "- Recursive Neural Networks\n",
    "- Hopfield Networks\n",
    "- Elman Networks and Jordan Networks\n",
    "- Echo State Networks\n",
    "- Neural history compressor\n",
    "- **The Long Short-Term Memory Model (LSTM)**\n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/v7p90neiaqghmpwawpiecmz9n7080m59.png\" alt=\"Representation of a Recurrent Neural Network\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##  <a id=\"lstm\"/>LSTM\n",
    "LSTM is one of the proposed solutions or upgrades to the **Recurrent Neural Network model**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "It is an abstraction of how computer memory works. It is \"bundled\" with whatever processing unit is implemented in the Recurrent Network, although outside of its flow, and is responsible for keeping, reading, and outputting information for the model. The way it works is simple: you have a linear unit, which is the information cell itself, surrounded by three logistic gates responsible for maintaining the data. One gate is for inputting data into the information cell, one is for outputting data from the input cell, and the last one is to keep or forget data depending on the needs of the network.\n",
    "\n",
    "Thanks to that, it not only solves the problem of keeping states, because the network can choose to forget data whenever information is not needed, it also solves the gradient problems, since the Logistic Gates have a very nice derivative.\n",
    "\n",
    "### Long Short-Term Memory Architecture\n",
    "\n",
    "As seen before, the Long Short-Term Memory is composed of a linear unit surrounded by three logistic gates. The name for these gates vary from place to place, but the most usual names for them are:\n",
    "- the \"Input\" or \"Write\" Gate, which handles the writing of data into the information cell, \n",
    "- the \"Output\" or \"Read\" Gate, which handles the sending of data back onto the Recurrent Network, and \n",
    "- the \"Keep\" or \"Forget\" Gate, which handles the maintaining and modification of the data stored in the information cell.\n",
    "\n",
    "<img src=\"https://ibm.box.com/shared/static/zx10duv5egw0baw6gh2hzsgr8ex45gsg.png\" width=\"720\"/>\n",
    "<center>*Diagram of the Long Short-Term Memory Unit*</center>\n",
    "\n",
    "The three gates are the centerpiece of the LSTM unit. The gates, when activated by the network, perform their respective functions. For example, the Input Gate will write whatever data it is passed onto the information cell, the Output Gate will return whatever data is in the information cell, and the Keep Gate will maintain the data in the information cell. These gates are analog and multiplicative, and as such, can modify the data based on the signal they are sent.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## <a id=\"build\"/> Building a LSTM with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### LSTM for Classification\n",
    "Although RNN is mostly used to model sequences and predict sequential data, we can still classify images using a LSTM network. If we consider every image row as a sequence of pixels, we can feed a LSTM network for classification. Lets use the famous MNIST dataset here. Because MNIST image shape is 28*28px, we will then handle 28 sequences of 28 steps for every sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### MNIST Dataset\n",
    "\n",
    "Tensor flow already provides **helper functions** to download and process the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "button": false,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-103-dd5674c2f727>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/mnist/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../data/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ../data/mnist/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ../data/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/ayman/anaconda3/envs/dltf/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../data/mnist\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The function **`input_data.read_data_sets(...)`** loads the entire dataset and returns an object **`tensorflow.contrib.learn.python.learn.datasets.mnist.DataSets`**\n",
    "\n",
    "\n",
    "The argument **(`one_hot=False`)** creates the label arrays as 10-dimensional binary vectors (only zeros and ones), in which the index cell for the number one, is the class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "button": false,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images:  (55000, 784)\n",
      "Train Labels   (55000, 10)\n",
      "Test Images:   (10000, 784)\n",
      "Test Labels:   (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "trainimgs = mnist.train.images\n",
    "trainlabels = mnist.train.labels\n",
    "testimgs = mnist.test.images\n",
    "testlabels = mnist.test.labels \n",
    "\n",
    "ntrain = trainimgs.shape[0]\n",
    "ntest = testimgs.shape[0]\n",
    "dim = trainimgs.shape[1]\n",
    "nclasses = trainlabels.shape[1]\n",
    "print (\"Train Images: \", trainimgs.shape)\n",
    "print (\"Train Labels  \", trainlabels.shape)\n",
    "print (\"Test Images:  \" , testimgs.shape)\n",
    "print (\"Test Labels:  \", testlabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Let's get one sample, just to understand the structure of MNIST dataset \n",
    "\n",
    "The next code snippet prints the **label vector** (one_hot format), **the class** and actual sample formatted as **image**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "button": false,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 100 - Class: [6] - Label Vector: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Sample: 101 - Class: [0] - Label Vector: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Sample: 102 - Class: [5] - Label Vector: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "samplesIdx = [100, 101, 102]  #<-- You can change these numbers here to see other samples\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.imshow(testimgs[samplesIdx[0]].reshape([28,28]), cmap='gray')\n",
    "\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(0,28,28), np.linspace(0,28,28))\n",
    "X =  xx ; Y =  yy\n",
    "Z =  100*np.ones(X.shape)\n",
    "\n",
    "img = testimgs[77].reshape([28,28])\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "ax.set_zlim((0,200))\n",
    "\n",
    "\n",
    "offset=200\n",
    "for i in samplesIdx:\n",
    "    img = testimgs[i].reshape([28,28]).transpose()\n",
    "    ax.contourf(X, Y, img, 200, zdir='z', offset=offset, cmap=\"gray\")\n",
    "    offset -= 100\n",
    "\n",
    "    ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_zticks([])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i in samplesIdx:\n",
    "    print (f\"Sample: {i} - Class: {np.nonzero(testlabels[i])[0]} - Label Vector: {testlabels[i]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "---\n",
    "### Let's Understand the parameters, inputs and outputs\n",
    "\n",
    "We will treat the MNIST image $\\in \\mathcal{R}^{28 \\times 28}$ as $28$ sequences of a vector $\\mathbf{x} \\in \\mathcal{R}^{28}$. \n",
    "\n",
    "#### Our simple RNN consists of  \n",
    "1. One input layer which converts a $28*28$ dimensional input to an $128$ dimensional hidden layer, \n",
    "2. One intermediate recurrent neural network (LSTM) \n",
    "3. One output layer which converts an $128$ dimensional output of the LSTM to $10$ dimensional output indicating a class label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "n_input = 28 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28 # timesteps\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 100\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Construct a Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The input should be a Tensor of shape: [batch_size, time_steps, input_dimension], but in our case it would be (?, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=\"float\", shape=[None, n_steps, n_input], name=\"x\") # Current data input shape: (batch_size, n_steps, n_input) [100x28x28]\n",
    "y = tf.placeholder(dtype=\"float\", shape=[None, n_classes], name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets create the weight and biases for the read out layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets define a lstm cell with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "__dynamic_rnn__ creates a recurrent neural network specified from __lstm_cell__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "outputs, states = tf.nn.dynamic_rnn(lstm_cell, inputs=x, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The output of the rnn would be a [100x28x128] matrix. we use the linear activation to map it to a [?x10 matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "output = tf.reshape(tf.split(outputs, 28, axis=1, num=None, name='split')[-1],[-1,128])\n",
    "pred = tf.matmul(output, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "__labels__ and __logits__ should be tensors of shape [100x10], lets check it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "button": false,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_3:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, we define the cost function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-114-901d12311984>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred ))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here we define the accuracy and evaluation methods to be used in the learning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Just recall that we will treat the MNIST image $\\in \\mathcal{R}^{28 \\times 28}$ as $28$ sequences of a vector $\\mathbf{x} \\in \\mathcal{R}^{28}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "button": false,
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    # Keep training until reach max iterations\n",
    "    while step * batch_size < training_iters:\n",
    "\n",
    "        # We will read a batch of 100 images [100 x 784] as batch_x\n",
    "        # batch_y is a matrix of [100x10]\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        # We consider each row of the image as one sequence\n",
    "        # Reshape data to get 28 seq of 28 elements, so that, batxh_x is [100x28x28]\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "    \n",
    "\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        \n",
    "        if step % display_step == 0:\n",
    "            # Calculate batch accuracy\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(f\"Iter  {str(step*batch_size)} \\\n",
    "                    Minibatch Loss= {loss:.6f} \\\n",
    "                    Training Accuracy= {acc:.5f}\")\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iter 1000, Minibatch Loss= 1.745812, Training Accuracy= 0.38000\n",
    "# Iter 2000, Minibatch Loss= 1.402737, Training Accuracy= 0.59000\n",
    "# Iter 3000, Minibatch Loss= 1.265577, Training Accuracy= 0.53000\n",
    "# Iter 4000, Minibatch Loss= 0.878468, Training Accuracy= 0.72000\n",
    "# Iter 5000, Minibatch Loss= 0.873283, Training Accuracy= 0.69000\n",
    "# Iter 6000, Minibatch Loss= 0.759069, Training Accuracy= 0.73000\n",
    "# Iter 7000, Minibatch Loss= 0.794320, Training Accuracy= 0.72000\n",
    "# Iter 8000, Minibatch Loss= 0.670941, Training Accuracy= 0.80000\n",
    "# Iter 9000, Minibatch Loss= 0.377154, Training Accuracy= 0.87000\n",
    "# Iter 10000, Minibatch Loss= 0.389945, Training Accuracy= 0.87000\n",
    "# Iter 11000, Minibatch Loss= 0.455586, Training Accuracy= 0.89000\n",
    "# Iter 12000, Minibatch Loss= 0.358114, Training Accuracy= 0.87000\n",
    "# Iter 13000, Minibatch Loss= 0.529083, Training Accuracy= 0.82000\n",
    "# Iter 14000, Minibatch Loss= 0.503623, Training Accuracy= 0.80000\n",
    "# Iter 15000, Minibatch Loss= 0.354179, Training Accuracy= 0.89000\n",
    "# Iter 16000, Minibatch Loss= 0.330228, Training Accuracy= 0.89000\n",
    "# Iter 17000, Minibatch Loss= 0.256999, Training Accuracy= 0.91000\n",
    "# Iter 18000, Minibatch Loss= 0.430895, Training Accuracy= 0.86000\n",
    "# Iter 19000, Minibatch Loss= 0.296778, Training Accuracy= 0.94000\n",
    "# Iter 20000, Minibatch Loss= 0.300537, Training Accuracy= 0.91000\n",
    "# Iter 21000, Minibatch Loss= 0.152064, Training Accuracy= 0.95000\n",
    "# Iter 22000, Minibatch Loss= 0.171339, Training Accuracy= 0.94000\n",
    "# Iter 23000, Minibatch Loss= 0.199591, Training Accuracy= 0.93000\n",
    "# Iter 24000, Minibatch Loss= 0.278094, Training Accuracy= 0.91000\n",
    "# Iter 25000, Minibatch Loss= 0.228313, Training Accuracy= 0.94000\n",
    "# Iter 26000, Minibatch Loss= 0.280122, Training Accuracy= 0.91000\n",
    "# Iter 27000, Minibatch Loss= 0.270435, Training Accuracy= 0.90000\n",
    "# Iter 28000, Minibatch Loss= 0.180006, Training Accuracy= 0.95000\n",
    "# Iter 29000, Minibatch Loss= 0.226623, Training Accuracy= 0.95000\n",
    "# Iter 30000, Minibatch Loss= 0.411448, Training Accuracy= 0.86000\n",
    "# Iter 31000, Minibatch Loss= 0.126177, Training Accuracy= 0.96000\n",
    "# Iter 32000, Minibatch Loss= 0.203962, Training Accuracy= 0.93000\n",
    "# Iter 33000, Minibatch Loss= 0.175170, Training Accuracy= 0.95000\n",
    "# Iter 34000, Minibatch Loss= 0.251397, Training Accuracy= 0.92000\n",
    "# Iter 35000, Minibatch Loss= 0.265452, Training Accuracy= 0.92000\n",
    "# Iter 36000, Minibatch Loss= 0.133000, Training Accuracy= 0.96000\n",
    "# Iter 37000, Minibatch Loss= 0.126946, Training Accuracy= 0.96000\n",
    "# Iter 38000, Minibatch Loss= 0.227503, Training Accuracy= 0.92000\n",
    "# Iter 39000, Minibatch Loss= 0.185537, Training Accuracy= 0.94000\n",
    "# Iter 40000, Minibatch Loss= 0.106320, Training Accuracy= 0.97000\n",
    "# Iter 41000, Minibatch Loss= 0.101958, Training Accuracy= 0.95000\n",
    "# Iter 42000, Minibatch Loss= 0.142191, Training Accuracy= 0.96000\n",
    "# Iter 43000, Minibatch Loss= 0.165939, Training Accuracy= 0.96000\n",
    "# Iter 44000, Minibatch Loss= 0.114892, Training Accuracy= 0.96000\n",
    "# Iter 45000, Minibatch Loss= 0.125258, Training Accuracy= 0.96000\n",
    "# Iter 46000, Minibatch Loss= 0.144988, Training Accuracy= 0.92000\n",
    "# Iter 47000, Minibatch Loss= 0.142561, Training Accuracy= 0.96000\n",
    "# Iter 48000, Minibatch Loss= 0.086887, Training Accuracy= 0.98000\n",
    "# Iter 49000, Minibatch Loss= 0.159883, Training Accuracy= 0.96000\n",
    "# Iter 50000, Minibatch Loss= 0.171655, Training Accuracy= 0.95000\n",
    "# Iter 51000, Minibatch Loss= 0.081570, Training Accuracy= 0.97000\n",
    "# Iter 52000, Minibatch Loss= 0.139028, Training Accuracy= 0.93000\n",
    "# Iter 53000, Minibatch Loss= 0.159480, Training Accuracy= 0.93000\n",
    "# Iter 54000, Minibatch Loss= 0.078100, Training Accuracy= 0.97000\n",
    "# Iter 55000, Minibatch Loss= 0.092740, Training Accuracy= 0.98000\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
